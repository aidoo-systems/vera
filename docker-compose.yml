version: "3.9"

# Ollama runs as a separate service in the OLLAMA repo and is shared via
# the external Docker network `ollama_network`. Start OLLAMA first:
#
#   cd ../OLLAMA && docker compose up -d
#   ../OLLAMA/scripts/pull-models.sh   # wait for health + pull models
#   cd ../VERA && docker compose up -d
#
# VERA's Ollama integration is optional â€” the app degrades gracefully if
# Ollama is unavailable (offline summaries still work).

services:
  postgres:
    image: postgres:16
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-vera}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-vera}
      - POSTGRES_DB=${POSTGRES_DB:-vera}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT:-5432}:5432"

  redis:
    image: redis:7
    ports:
      - "${REDIS_PORT:-6379}:6379"

  backend:
    build: ./backend
    environment:
      - BACKEND_PORT=${BACKEND_PORT:-8000}
      - DATA_DIR=${DATA_DIR:-/data}
      - DATABASE_URL=${DATABASE_URL:-postgresql+psycopg://vera:vera@postgres:5432/vera}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND:-redis://redis:6379/0}
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
      - OLLAMA_TIMEOUT=${OLLAMA_TIMEOUT:-300}
    volumes:
      - ./data:${DATA_DIR:-/data}
    ports:
      - "${BACKEND_PORT:-4000}:8000"
    depends_on:
      - postgres
      - redis
    networks:
      - default
      - ollama_network

  worker:
    build: ./backend
    command: ["celery", "-A", "app.worker.celery_app", "worker", "--loglevel=info", "--concurrency=2"]
    environment:
      - DATA_DIR=${DATA_DIR:-/data}
      - DATABASE_URL=${DATABASE_URL:-postgresql+psycopg://vera:vera@postgres:5432/vera}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND:-redis://redis:6379/0}
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
      - OLLAMA_TIMEOUT=${OLLAMA_TIMEOUT:-300}
    volumes:
      - ./data:${DATA_DIR:-/data}
    depends_on:
      - postgres
      - redis
    networks:
      - default
      - ollama_network

  frontend:
    build: ./frontend
    environment:
      - FRONTEND_PORT=${FRONTEND_PORT:-3000}
      - NEXT_PUBLIC_API_BASE_URL=${NEXT_PUBLIC_API_BASE_URL:-http://localhost:4000}
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    depends_on:
      - backend

volumes:
  postgres_data:

networks:
  ollama_network:
    external: true
    name: ollama_network
